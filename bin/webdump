#!/bin/bash

#               _         _
# __      _____| |__   __| |_   _ _ __ ___  _ __
# \ \ /\ / / _ \ '_ \ / _` | | | | '_ ` _ \| '_ \
#  \ V  V /  __/ |_) | (_| | |_| | | | | | | |_) |
#   \_/\_/ \___|_.__/ \__,_|\__,_|_| |_| |_| .__/
#                                          |_|
#
# Publish files on your own webserver. Put them in a hard-to-guess
# directory. Clean up expired files.

# Dependencies:
#
#     - randgen-catchy  (you can find it in this repo, too)
#     - rsync over ssh

# Exemplary ~/.webdump:
#
#     localbase=~/www/temporary-dump
#     remotebase=bob@alice:/srv/http/vhosts/dump
#     urlbase=http://dump.example.com
#
# Note that you don't need to use a config file. You can simply export
# those variables.

if [[ -z "$localbase" ]] || [[ -z "$remotebase" ]] || [[ -z "$urlbase" ]]
then
    . ~/.webdump
fi

if [[ -z "$localbase" ]] || [[ -z "$remotebase" ]] || [[ -z "$urlbase" ]]
then
    echo 'No settings found. Aborting.' >&2
    exit 1
fi

# Take care of expiry date.
now=$(date +%s)
expiry_minutes=$((60 * 24 * 7))

autoindex=1

while getopts mhdwMDAf: name
do
    case "$name" in
        m) expiry_minutes=$((1)) ;;
        h) expiry_minutes=$((60)) ;;
        d) expiry_minutes=$((60 * 24)) ;;
        w) true ;;  # keep default
        M) expiry_minutes=$((60 * 24 * 30)) ;;
        D) delete=1 ;;
        A) autoindex=0 ;;
        f) expiry_minutes=$OPTARG ;;
    esac
done
shift $((OPTIND - 1))

expiry=$((expiry_minutes * 60))
expiry_human=$(date -d "@$((now + expiry))" '+%a, %F, %T')

# Create base directory for new files (if needed).
if (( $# > 0 ))
then
    prefix=$(randgen-catchy -w 2)
    mkdir -p "$localbase"/"$prefix"
    echo $((now + expiry)) >"$localbase"/"$prefix".expiry
else
    echo "Usage: $0 [OPTION...] FILE [FILE...]" >&2
    exit 1
fi

# Copy files and keep track of paths and URLs.
urls=()
locals=()
for i
do
    cp -avi -- "$i" "$localbase"/"$prefix"

    bn=$(basename -- "$i")
    ebn=$(python3 -c \
        'from urllib.parse import quote as q, sys; print(q(sys.argv[1]))' "$bn")
    urls+=("$urlbase"/"$prefix"/"$ebn")
    locals+=("$localbase"/"$prefix"/"$bn")

    (( delete )) && rm -Rfv -- "$i"
done

# Make everything world readable.
find "$localbase"/"$prefix" -type d -exec chmod 0755 '{}' '+'
find "$localbase"/"$prefix" -type f -exec chmod 0644 '{}' '+'

if (( autoindex )) && which make-html-index >/dev/null 2>&1
then
    (
        cd "$localbase"/"$prefix"
        make-html-index
    )
fi

# Get all files that are currently stored on the remote host. Why?
# Because this allows you to use the same dump area from multiple
# clients: When client A creates new files, client B retrieves them
# first before calling "rsync --delete ..." (which would otherwise erase
# them).
rsync -avzP -e ssh "$remotebase"/ "$localbase"

# Remove expired files.
(
shopt -s nullglob
for i in "$localbase"/*.expiry
do
    expiry=$(< "$i")
    if (( now > expiry ))
    then
        rm -Rfv -- "$i" "${i%.expiry}"
    fi
done
)

# Push new data set to remote.
rsync -avzP --delete -e ssh "$localbase"/ "$remotebase"

# Informational banner.
if (( expiry_minutes >= 60 * 24 ))
then
    expiry_duration_human="~$((expiry_minutes / (60 * 24))) day(s)"
elif (( expiry_minutes >= 60 ))
then
    expiry_duration_human="~$((expiry_minutes / 60)) hour(s)"
else
    expiry_duration_human="$expiry_minutes minute(s)"
fi

if (( "${#urls[@]}" > 0 ))
then
    IFS=$'\n'
    cat <<EOF


$(tput bold)Local:$(tput sgr0)
${locals[*]}

$(tput bold)Public:$(tput sgr0)
$(tput smul)$urlbase/$prefix
${urls[*]}$(tput sgr0)

$(tput bold)Expiry: $(tput setaf 3)$expiry_human
        $(tput sgr0)$(tput bold)$expiry_duration_human$(tput sgr0)
EOF
fi
